{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#creating a testing mode\n",
    "mode = 'test'\n",
    "directory = 'asl_video_capture_data/'+mode+'/'\n",
    "\n",
    "#creating variable to count frames\n",
    "i=0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Printing the count in each set to the screen\n",
    "    cv2.putText(frame, \"MODE : \"+mode, (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"IMAGE COUNT\", (10, 100), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "\n",
    "    # Coordinates of the ROI\n",
    "    x1 = int(0.5*frame.shape[1])\n",
    "    y1 = 10\n",
    "    x2 = frame.shape[1]-10\n",
    "    y2 = int(0.5*frame.shape[1])\n",
    "\n",
    "    # Drawing the ROI\n",
    "    # The increment/decrement by 1 is to compensate for the bounding box\n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255,0,0) ,1)\n",
    "    # Extracting the ROI\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    roi = cv2.resize(roi, (64, 64)) \n",
    "\n",
    "    #roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    #_, roi = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    i += 10\n",
    "    if (i%200 == 0):\n",
    "        cv2.imwrite('C://project_folder/practice_1/ASL/archive (1)/asl_alphabet_test/asl_alphabet_test/test' + str(i) + '.jpg',roi)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "\n",
    "    if cv2.waitKey(40) ==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'C://project_folder/practice_1/ASL/archive (1)/asl_alphabet_test/asl_alphabet_test'\n",
    "def load_test_data():\n",
    "    images = []\n",
    "    names = []\n",
    "    size = 64,64\n",
    "    for image in os.listdir(test_dir):\n",
    "        temp = cv2.imread(test_dir + '/' + image)\n",
    "        temp = cv2.resize(temp, size)\n",
    "        #temp  = cv2.flip(temp, 1)\n",
    "        images.append(temp)\n",
    "        names.append(image)\n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    return images, names\n",
    "\n",
    "test_images, test_img_names = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                14877     \n",
      "=================================================================\n",
      "Total params: 942,557\n",
      "Trainable params: 942,045\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"asl_train_models.h5\")\n",
    "\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F336C4D8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[25 24 25 13 18 28 28 23 23 23 23 25 18 23 28 20 28  7 17 20 17 17 17 20\n",
      " 20  4  1 18  1 18 28 18 13 23 23 25]\n"
     ]
    }
   ],
   "source": [
    "predictions = new_model.predict([test_images])\n",
    "#print(predictions)\n",
    "classes = np.argmax(predictions, axis =1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'Y', 'Z', 'N', 'S', 'nothing', 'nothing', 'X', 'X', 'X', 'X', 'Z', 'S', 'X', 'nothing', 'U', 'nothing', 'H', 'R', 'U', 'R', 'R', 'R', 'U', 'U', 'E', 'B', 'S', 'B', 'S', 'nothing', 'S', 'N', 'X', 'X', 'Z']\n"
     ]
    }
   ],
   "source": [
    "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
    "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
    "                   'Z':25,'space':26,'del':27,'nothing':28}\n",
    "voice = []\n",
    "for i in range(classes.shape[0]):\n",
    "    for j, k in labels_dict.items():\n",
    "        if(classes[i]== labels_dict[j]):\n",
    "            voice.append(j)\n",
    "print(voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "for i in voice:\n",
    "    tts = gTTS(str(voice))\n",
    "tts.save('asl_to_speech.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in c:\\users\\raghu\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: click in c:\\users\\raghu\\anaconda3\\lib\\site-packages (from gtts) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\raghu\\appdata\\roaming\\python\\python38\\site-packages (from gtts) (1.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\raghu\\anaconda3\\lib\\site-packages (from gtts) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\raghu\\anaconda3\\lib\\site-packages (from requests->gtts) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\raghu\\anaconda3\\lib\\site-packages (from requests->gtts) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raghu\\anaconda3\\lib\\site-packages (from requests->gtts) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\raghu\\anaconda3\\lib\\site-packages (from requests->gtts) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing os module\n",
    "import os\n",
    "#providing the path of the folder\n",
    "#r = raw string literal\n",
    "folder_path = ('C://project_folder/practice_1/ASL/archive (1)/asl_alphabet_test/asl_alphabet_test')\n",
    "#using listdir() method to list the files of the folder\n",
    "test = os.listdir(folder_path)\n",
    "#taking a loop to remove all the images\n",
    "#using \".png\" extension to remove only png images\n",
    "#using os.remove() method to remove the files\n",
    "for images in test:\n",
    "    if images.endswith(\".png\"):\n",
    "        os.remove(os.path.join(folder_path, images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
